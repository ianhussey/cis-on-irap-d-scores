---
title: "Bootstrapped estimation of D scores for individual participants"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# Overview 

IRAP trial type D scores are calculated from an average of only 18 pairs of reaction times. This would be deemed as far too low anywhere else in the literature on reaction time based tasks. The implications of this can be seen in how poorly estimated any one IRAP D score is. We can observe this by bootstrapping reaction times for each participant's D scores and noting how wide their confidence intervals are.

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE,
                      cache.lazy=FALSE)
```

```{r}

# dependencies
library(tidyverse)
library(knitr)
library(kableExtra)
library(rsample)
library(broom)
library(purrr)
library(furrr)
library(pim)
library(boot)
library(parallel)
library(bayestestR)
library(afex)
library(lsmeans)
library(patchwork)
library(mdthemes)
library(lme4)
library(sjPlot)
library(emmeans)

# set seed for reproducibility
set.seed(42)

# number of bootstraps
n_boots <- 2000 

# run furrr:::future_map in parallel
plan(multiprocess)

# options
options(knitr.table.format = "html") # necessary configuration of tables

# disable scientific notation
options(scipen = 999) 


# function to round all numeric vars in a data frame
round_df <- function(df, n_digits = 3) {
  df %>% mutate_if(is.numeric, round, digits = n_digits)
}


# get data from evaluative IRAPs
data_trial_level <- read_csv("../data/data_trial_level.csv") %>%
  filter(timepoint == "baseline")

# outliers
data_outliers <- data_trial_level %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  select(unique_id, domain, mean_rt) %>%
  mutate(median_mean_rt = median(mean_rt, na.rm = TRUE),
         mad_mean_rt = mad(mean_rt, na.rm = TRUE)) %>%
  # exclude median +- 2MAD
  mutate(rt_outlier = ifelse(mean_rt < median_mean_rt-mad_mean_rt*2 |
                               mean_rt > median_mean_rt+mad_mean_rt*2, TRUE, FALSE)) %>%
  filter(rt_outlier == FALSE) %>%
  select(unique_id, rt_outlier) %>%
  full_join(data_trial_level, by = "unique_id") %>%
  mutate(rt_outlier = ifelse(is.na(rt_outlier), TRUE, rt_outlier))

data_outliers_removed <- data_outliers %>%
  filter(rt_outlier == FALSE)

# trim RTs>10000 ms, as part of D scoring
data_trimmed <- data_outliers_removed %>%
  select(unique_id, domain, trial_type, rt, block_type) %>%
  filter(rt <= 10000)

```

# Descriptives

```{r}

data_outliers %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(rt_outlier) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives <- data_outliers_removed %>%
  distinct(unique_id, .keep_all = TRUE)

data_descriptives %>%
  count(domain) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives %>%
  count(domain) %>%
  summarize(total_n = sum(n),
            min_n_per_domain = min(n),
            max_n_per_domain = max(n),
            mean_n_per_domain = round(mean(n, na.rm = TRUE), 2),
            sd_n_per_domain = round(sd(n, na.rm = TRUE), 2)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives %>%
  summarize(min_age = round(min(age, na.rm = TRUE), 2),
            max_age = round(max(age, na.rm = TRUE), 2),
            mean_age = round(mean(age, na.rm = TRUE), 2),
            sd_age = round(sd(age, na.rm = TRUE), 2)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives %>%
  count(gender) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Distribution of RTs

```{r}

ggplot(data_trimmed, aes(rt, fill = block_type)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~ trial_type)

data_trimmed %>%
  group_by(trial_type, block_type) %>%
  summarize(mean = mean(rt, na.rm = TRUE),
            sd = sd(rt, na.rm = TRUE)) %>%
  round_df(0) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Bootstrap 95% CIs on D scores

## *D* scores calculated by trial-type

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_estimates_D.rds")) {
  
  data_estimates_D <- read_rds("models/data_estimates_D.rds")
  
} else {
  
  D_score <- function(data, i) {
    data_with_indexes <- data[i,] # boot function requires data and index
    mean_con <- mean(data_with_indexes$rt[data_with_indexes$block_type == "con"], na.rm = TRUE)
    mean_incon <- mean(data_with_indexes$rt[data_with_indexes$block_type == "incon"], na.rm = TRUE)
    sd <- sd(data_with_indexes$rt, na.rm = TRUE)
    D <- (mean_incon - mean_con) / sd
    return(D)
  }
  
  bootstrap_D_score <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = D_score, 
                 R         = n_boots, 
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores())
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("norm","basic", "perc", "bca"))
    
    output <- 
      tibble(method   = c("normal", "basic", "percent", "bca"),
             estimate = rep(fit$t0, 4),
             ci_lower = c(results$normal[2], results$basic[4], results$percent[4], results$bca[4]),
             ci_upper = c(results$normal[3], results$basic[5], results$percent[5], results$bca[5]))
    
    return(output)
  }
  
  # bootstrap D scores 
  data_estimates_D <- data_trimmed %>%
    select(unique_id, domain, trial_type, rt, block_type) %>%
    group_by(unique_id, domain, trial_type) %>%
    do(bootstrap_D_score(data = .)) %>%
    ungroup() %>%
    mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) %>%
    round_df(3)
  
  # save to disk
  write_rds(data_estimates_D, "models/data_estimates_D.rds", compress = "gz")
  
}

```

## PI scores calculated by trial-type

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_estimates_PI.rds")) {
  
  data_estimates_PI <- read_rds("models/data_estimates_PI.rds")
  
} else {
  
  # Fast calculation of the A statistic - code from Ruscio (2008) supplementary materials
  PI_score <- function(data, i) {
    data_with_indexes <- data[i,] # boot function requires data and index
    x  <- na.omit(data_with_indexes$rt[data_with_indexes$block_type == "con"])
    y  <- na.omit(data_with_indexes$rt[data_with_indexes$block_type == "incon"])
    nx <- length(x)
    ny <- length(y)
    rx <- sum(rank(c(x, y))[1:nx])
    PI <- (rx / nx - (nx + 1) / 2) / ny
    return(PI)
  }
  
  bootstrap_PI_score <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = PI_score, 
                 R         = n_boots, 
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores())
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("norm","basic", "perc", "bca"))
    
    output <- 
      tibble(method   = c("normal", "basic", "percent", "bca"),
             estimate = rep(fit$t0, 4),
             ci_lower = c(results$normal[2], results$basic[4], results$percent[4], results$bca[4]),
             ci_upper = c(results$normal[3], results$basic[5], results$percent[5], results$bca[5]))
    
    return(output)
  }
  
  # bootstrap PI scores 
  data_estimates_PI <- data_outliers_removed %>%
    group_by(unique_id, domain, trial_type) %>%
    do(bootstrap_PI_score(data = .)) %>%
    ungroup() %>%
    mutate(sig = ifelse((ci_lower < 0.50 & ci_upper < 0.50) | (ci_lower > 0.50 & ci_upper > 0.50), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) %>%
    round_df(3)
  
  # save to disk
  write_rds(data_estimates_PI, "models/data_estimates_PI.rds", compress = "gz")
  
}

```

# Proportion different from zero

## By trial type

Data is split by domain and method but this is not shown in the plot. All domains are collated, and only the BCA method is plotted (as the arguably most appropriate method and also the most favorable one in terms of the results).

```{r}

data_estimates_D %>%
  filter(method == "bca") %>%
  arrange(estimate) %>%
  group_by(trial_type) %>%
  mutate(ordered_id = row_number()) %>%
  ungroup() %>%
  mutate(trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4")) %>%
  ggplot() +
  geom_linerange(aes(x = ordered_id, ymin = ci_lower, ymax = ci_upper, color = sig),
                 alpha = 1) +
  geom_point(aes(ordered_id, estimate), size = 0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_linedraw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        legend.position = c(0.20, 0.85)) +
  scale_color_viridis_d(end = 0.6, direction = -1) +
  xlab("Participant (ranked by D score)") +
  ylab("IRAP D score") +
  labs(color = "95% CI excludes zero") + 
  facet_wrap(~ trial_type)

```

## By domain and trial type 

```{r fig.height=25, fig.width=7}

# separated by domain
data_estimates_D %>%
  filter(method == "bca") %>%
  arrange(trial_type, domain, estimate) %>%
  group_by(trial_type, domain) %>%
  mutate(ordered_id = row_number()/n()) %>%
  ungroup() %>%
  ggplot() +
  geom_linerange(aes(x = ordered_id, ymin = ci_lower, ymax = ci_upper, color = sig),
                 alpha = 1) +
  geom_point(aes(ordered_id, estimate), size = 0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = c(0.20, 0.85)) +
  scale_color_viridis_d(end = 0.6, direction = -1) +
  xlab("Participant (ranked by D score)") +
  ylab("IRAP D score") +
  labs(color = "95% CI excludes zero") + 
  facet_wrap(~domain + trial_type, ncol = 8)

```

## Model

```{r}

# combine
data_diff_zero <- 
  bind_rows(mutate(data_estimates_D, DV_type = "*D* scores"),
            mutate(data_estimates_PI, DV_type = "PI scores")) %>%
    mutate(domain = as.factor(domain),
           method = fct_relevel(method, "bca", "basic", "normal", "percent"),
           trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4")) %>%
  group_by(domain, trial_type, method, DV_type) %>%
  summarize(proportion_diff_zero = mean(sig),
            variance = plotrix::std.error(sig)^2,
            .groups = "drop") %>%
  mutate(variance = ifelse(variance == 0, 0.000001, variance))  # model cannot be run on zero variance, so offset

# fit model
fit_diff_zero <- 
  lmer(proportion_diff_zero ~ 1 + trial_type * method * DV_type + (1 | domain),
       weights = 1/variance, 
       data = data_diff_zero)
       # control = lmerControl(check.nobs.vs.nlev = "ignore", 
       #                       check.nobs.vs.nRE = "ignore"))

# results table
tab_model(fit_diff_zero, 
          string.p = "p (corrected)", 
          ci.hyphen = ", ",
          #emph.p = FALSE,
          p.adjust = "holm")

# extract marginal means
results_emm_diff_zero <- 
  summary(emmeans(fit_diff_zero, ~ DV_type | trial_type + method)) %>%
  select(DV_type, trial_type, method, estimate = emmean, ci_lower = lower.CL, ci_upper = upper.CL) %>%
  mutate(method = fct_relevel(method, "bca", "basic", "normal", "percent"),
         trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4"))
  
p_diff_zero <- 
  ggplot(results_emm_diff_zero, aes(trial_type, estimate, color = method, shape = method, group = method)) +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = dodge_width)) +
  geom_line(position = position_dodge(width = dodge_width)) +
  geom_point(position = position_dodge(width = dodge_width), size = 2.5) +
  facet_wrap(~ DV_type, ncol = 1, nrow = 2) +
  scale_shape_discrete(labels = c("BCA", "Basic", "Normal", "Percentile")) +
  scale_color_viridis_d(end = 0.8, labels = c("BCA", "Basic", "Normal", "Percentile")) +
  mdthemes::md_theme_linedraw() +
  scale_x_discrete(labels = c("tt1" = "1", "tt2" = "2", "tt3" = "3", "tt4" = "4")) +
  labs(x = "Trial type",
       y = "Proportion of non-zero scores",
       color = "Bootstrap method",
       shape = "Bootstrap method") + 
  theme(legend.position = "top")

p_diff_zero

```

# Proportion different from one another

Within domain and trial type

## Calculate discriminability

Many have argued that the zero point is arbitrary and not a useful reference point. Instead of asking "what proportion of *D*/PI scores are different from zero?", we could also ask "what proportion of *D*/PI scores are different from one another?"

### *D* scores

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_discriminability_D.rds")) {
  
  data_discriminability_D <- read_rds("models/data_discriminability_D.rds")
  
} else {
  
  # helper function to apply workflow to each resample
  discriminability <- function(data, i) {
    
    data_with_indexes <- data[i,] # boot function requires data and index
    
    estimate <- data_with_indexes$estimate
    ci_lower <- data_with_indexes$ci_lower
    ci_upper <- data_with_indexes$ci_upper
    
    n_estimate <- length(estimate)
    n_ci_lower <- length(ci_lower)
    n_ci_upper <- length(ci_upper)
    
    r_estimate <- sum(rank(c(estimate, ci_lower))[1:n_estimate])
    r_ci_upper <- sum(rank(c(ci_upper, estimate))[1:n_ci_upper])
    
    prob_estimate_inferior_to_ci_lower <- 1 - (r_estimate / n_estimate - (n_estimate + 1) / 2) / n_ci_lower
    prob_estimate_superior_to_ci_upper <- 1 - (r_ci_upper / n_ci_upper - (n_ci_upper + 1) / 2) / n_estimate
    
    probability_estimates_outside_cis <- (prob_estimate_inferior_to_ci_lower + prob_estimate_superior_to_ci_upper)
    
    return(probability_estimates_outside_cis)
    
  }
  
  bootstrap_discriminability <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = discriminability, 
                 R         = n_boots,
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores())
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("norm","basic", "perc", "bca"))
    
    output <- 
      tibble(method   = c("normal", "basic", "percent", "bca"),
             estimate = rep(fit$t0, 4),
             ci_lower = c(results$normal[2], results$basic[4], results$percent[4], results$bca[4]),
             ci_upper = c(results$normal[3], results$basic[5], results$percent[5], results$bca[5]))
    
    return(output)
  }

  # bootstrap D scores 
  data_discriminability_D <- data_estimates_D %>%
    select(unique_id, domain, trial_type, estimate, ci_upper, ci_lower) %>%
    group_by(domain, trial_type) %>%
    do(bootstrap_discriminability(data = .)) %>%
    ungroup() %>%
    mutate(proportion_discriminable = estimate,
           variance = ((ci_upper - ci_lower)/(1.96*2))^2) %>%
    mutate(domain = as.factor(domain),
           method = fct_relevel(method, "bca", "basic", "normal", "percent"),
           trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4"),
           DV_type = "*D* scores")
  
  # save to disk
  write_rds(data_discriminability_D, "models/data_discriminability_D.rds", compress = "gz")
  
}

```

### PI scores

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_discriminability_PI.rds")) {
  
  data_discriminability_PI <- read_rds("models/data_discriminability_PI.rds")
  
} else {
  
  # bootstrap D scores 
  data_discriminability_PI <- data_estimates_PI %>%
    select(unique_id, domain, trial_type, estimate, ci_upper, ci_lower) %>%
    group_by(domain, trial_type) %>%
    do(bootstrap_discriminability(data = .)) %>%
    ungroup() %>%
    mutate(proportion_discriminable = estimate,
           variance = ((ci_upper - ci_lower)/(1.96*2))^2) %>%
    mutate(domain = as.factor(domain),
           method = fct_relevel(method, "bca", "basic", "normal", "percent"),
           trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4"),
           DV_type = "PI scores")
  
  # save to disk
  write_rds(data_discriminability_PI, "models/data_discriminability_PI.rds", compress = "gz")
  
}

```

## Model

```{r}

# combine
data_discriminability_combined <- 
  bind_rows(data_discriminability_D,
            data_discriminability_PI)

# fit meta analytic model
fit_disciminability <- 
  lmer(proportion_discriminable ~ 1 + trial_type * method * DV_type + (1 | domain), 
       weights = 1/variance, 
       data = data_discriminability_combined)
       # control = lmerControl(check.nobs.vs.nlev = "ignore", 
       #                       check.nobs.vs.nRE = "ignore"))

# results table
tab_model(fit_disciminability, 
          string.p = "p (corrected)", 
          ci.hyphen = ", ",
          #emph.p = FALSE,
          p.adjust = "holm")

# extract marginal means
results_emm_disciminability <- 
  summary(emmeans(fit_disciminability, ~ DV_type | trial_type + method)) %>%
  select(DV_type, trial_type, method, estimate = emmean, ci_lower = lower.CL, ci_upper = upper.CL) %>%
  mutate(method = fct_relevel(method, "bca", "basic", "normal", "percent"),
         trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4"))
  
p_disciminability <- 
  ggplot(results_emm_disciminability, aes(trial_type, estimate, color = method, shape = method, group = method)) +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = dodge_width)) +
  geom_line(position = position_dodge(width = dodge_width)) +
  geom_point(position = position_dodge(width = dodge_width), size = 2.5) +
  facet_wrap(~ DV_type, ncol = 1, nrow = 2) +
  scale_shape_discrete(labels = c("BCA", "Basic", "Normal", "Percentile")) +
  scale_color_viridis_d(end = 0.8, labels = c("BCA", "Basic", "Normal", "Percentile")) +
  mdthemes::md_theme_linedraw() +
  scale_x_discrete(labels = c("tt1" = "1", "tt2" = "2", "tt3" = "3", "tt4" = "4")) +
  labs(x = "Trial type",
       y = "Proportion of discriminable scores",
       color = "Bootstrap method",
       shape = "Bootstrap method") + 
  theme(legend.position = "top")

p_disciminability

```

# CI widths NEEDED

meta analyze estimation widths

```{r}


```

# CI widths as a proportion of observed range

Wilkinson notation for model: ci_width_proportion ~ trial_type * method * DV_type + (1 | domain/unique_id)

```{r}

## calculate observed ranges 
observed_range_estimates_D <- data_estimates_D %>%
  group_by(domain, method, trial_type) %>%
  dplyr::summarize(min = min(estimate, na.rm = TRUE),
                   max = max(estimate, na.rm = TRUE),
                   .groups = "drop") %>%
  mutate(range = max - min) 

observed_range_estimates_PI <- data_estimates_PI %>%
  group_by(domain, method, trial_type) %>%
  dplyr::summarize(min = min(estimate, na.rm = TRUE),
                   max = max(estimate, na.rm = TRUE),
                   .groups = "drop") %>%
  mutate(range = max - min) 


# calculate CI / range 
data_ci_width_proportions_D <- data_estimates_D %>%
  # join this data into the original data
  full_join(observed_range_estimates_D, by = c("domain", "method", "trial_type")) %>%
  # calculate ci width as a proportion of observed range
  mutate(ci_width_proportion = ci_width / range) %>%
  mutate(DV_type = "*D* scores") 

data_ci_width_proportions_PI <- data_estimates_PI %>%
  # join this data into the original data
  full_join(observed_range_estimates_PI, by = c("domain", "method", "trial_type")) %>%
  # calculate ci width as a proportion of observed range
  mutate(ci_width_proportion = ci_width / range) %>%
  mutate(DV_type = "PI scores")

# combine
data_ci_width_proportions_combined <- 
  bind_rows(data_ci_width_proportions_D,
            data_ci_width_proportions_PI) %>%
  mutate(domain = as.factor(domain),
         method = fct_relevel(method, "bca", "basic", "normal", "percent"),
         trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4"))


# fit model
fit <- lme4::lmer(ci_width_proportion ~ trial_type * method * DV_type + (1 | domain/unique_id),
                  data = data_ci_width_proportions_combined)


# results table
tab_model(fit, 
          string.p = "p (corrected)", 
          ci.hyphen = ", ",
          #emph.p = FALSE,
          p.adjust = "holm")

# plot
dodge_width <- 0.25

# extract marginal means
results_emm_ci_width_proportions <- 
  summary(emmeans(fit, ~ DV_type | trial_type + method)) %>%
  select(DV_type, trial_type, method, estimate = emmean, ci_lower = asymp.LCL, ci_upper = asymp.UCL) %>%
  mutate(method = fct_relevel(method, "bca", "basic", "normal", "percent"),
         trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4"))
  
p_ci_width_proportions <- 
  ggplot(results_emm_ci_width_proportions, aes(trial_type, estimate, color = method, shape = method, group = method)) +
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper), position = position_dodge(width = dodge_width)) +
  geom_line(position = position_dodge(width = dodge_width)) +
  geom_point(position = position_dodge(width = dodge_width), size = 2.5) +
  facet_wrap(~ DV_type, ncol = 1, nrow = 2) +
  scale_shape_discrete(labels = c("BCA", "Basic", "Normal", "Percentile")) +
  scale_color_viridis_d(end = 0.8, labels = c("BCA", "Basic", "Normal", "Percentile")) +
  mdthemes::md_theme_linedraw() +
  scale_x_discrete(labels = c("tt1" = "1", "tt2" = "2", "tt3" = "3", "tt4" = "4")) +
  labs(x = "Trial type",
       y = "95% CI width / observed range",
       color = "Bootstrap method",
       shape = "Bootstrap method") + 
  theme(legend.position = "top")

p_ci_width_proportions

```

# Session info

```{r}

sessionInfo()

```
