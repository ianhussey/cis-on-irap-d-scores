---
title: "Bootstrapped estimation of D scores for individual participants"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# Overview 

IRAP trial type D scores are calculated from an average of only 18 pairs of reaction times. This would be deemed as far too low anywhere else in the literature on reaction time based tasks. The implications of this can be seen in how poorly estimated any one IRAP D score is. We can observe this by bootstrapping reaction times for each participant's D scores and noting how wide their confidence intervals are.

```{r, include=FALSE}
knitr::opts_chunk$set(message=FALSE,
                      warning=FALSE,
                      cache.lazy=FALSE)
```

```{r}

# dependencies
library(tidyverse)
library(knitr)
library(kableExtra)
library(rsample)
library(broom)
library(purrr)
library(furrr)
library(pim)
library(boot)
library(parallel)
library(bayestestR)
library(afex)
library(lsmeans)
library(ggsci)
library(patchwork)
library(mdthemes)

# set seed for reproducibility
set.seed(42)

# number of bootstraps
n_boots <- 2000 

# run furrr:::future_map in parallel
plan(multiprocess)

# options
options(knitr.table.format = "html") # necessary configuration of tables

# disable scientific notation
options(scipen = 999) 


# function to round all numeric vars in a data frame
round_df <- function(df, n_digits = 3) {
  df %>% mutate_if(is.numeric, round, digits = n_digits)
}


# get data from evaluative IRAPs
data_trial_level <- read_csv("../data/data_trial_level.csv") %>%
  filter(timepoint == "baseline")

# outliers
data_outliers <- data_trial_level %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  select(unique_id, domain, mean_rt) %>%
  mutate(median_mean_rt = median(mean_rt, na.rm = TRUE),
         mad_mean_rt = mad(mean_rt, na.rm = TRUE)) %>%
  # exclude median +- 2MAD
  mutate(rt_outlier = ifelse(mean_rt < median_mean_rt-mad_mean_rt*2 |
                               mean_rt > median_mean_rt+mad_mean_rt*2, TRUE, FALSE)) %>%
  filter(rt_outlier == FALSE) %>%
  select(unique_id, rt_outlier) %>%
  full_join(data_trial_level, by = "unique_id") %>%
  mutate(rt_outlier = ifelse(is.na(rt_outlier), TRUE, rt_outlier))

data_outliers_removed <- data_outliers %>%
  filter(rt_outlier == FALSE)

# trim RTs>10000 ms, as part of D scoring
data_trimmed <- data_outliers_removed %>%
  select(unique_id, domain, trial_type, rt, block_type) %>%
  filter(rt <= 10000)

```

# Descriptives

```{r}

data_outliers %>%
  distinct(unique_id, .keep_all = TRUE) %>%
  count(rt_outlier) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives <- data_outliers_removed %>%
  distinct(unique_id, .keep_all = TRUE)

data_descriptives %>%
  count(domain) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives %>%
  count(domain) %>%
  summarize(total_n = sum(n),
            min_n_per_domain = min(n),
            max_n_per_domain = max(n),
            mean_n_per_domain = round(mean(n, na.rm = TRUE), 2),
            sd_n_per_domain = round(sd(n, na.rm = TRUE), 2)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives %>%
  summarize(min_age = round(min(age, na.rm = TRUE), 2),
            max_age = round(max(age, na.rm = TRUE), 2),
            mean_age = round(mean(age, na.rm = TRUE), 2),
            sd_age = round(sd(age, na.rm = TRUE), 2)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_descriptives %>%
  count(gender) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Distribution of RTs

```{r}

ggplot(data_trimmed, aes(rt, fill = block_type)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~ trial_type)

data_trimmed %>%
  group_by(trial_type, block_type) %>%
  summarize(mean = mean(rt, na.rm = TRUE),
            sd = sd(rt, na.rm = TRUE)) %>%
  round_df(0) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

# Bootstrap 95% CIs on D scores

## *D* scores calculated by trial-type

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_estimates_D.rds")) {
  
  data_estimates_D <- read_rds("models/data_estimates_D.rds")
  
} else {
  
  D_score <- function(data, i) {
    data_with_indexes <- data[i,] # boot function requires data and index
    mean_con <- mean(data_with_indexes$rt[data_with_indexes$block_type == "con"], na.rm = TRUE)
    mean_incon <- mean(data_with_indexes$rt[data_with_indexes$block_type == "incon"], na.rm = TRUE)
    sd <- sd(data_with_indexes$rt, na.rm = TRUE)
    D <- (mean_incon - mean_con) / sd
    return(D)
  }
  
  bootstrap_D_score <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = D_score, 
                 R         = n_boots, 
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores())
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("norm","basic", "perc", "bca"))
    
    output <- 
      tibble(method   = c("normal", "basic", "percent", "bca"),
             estimate = rep(fit$t0, 4),
             ci_lower = c(results$normal[2], results$basic[4], results$percent[4], results$bca[4]),
             ci_upper = c(results$normal[3], results$basic[5], results$percent[5], results$bca[5]))
    
    return(output)
  }
  
  # bootstrap D scores 
  data_estimates_D <- data_trimmed %>%
    select(unique_id, domain, trial_type, rt, block_type) %>%
    group_by(unique_id, domain, trial_type) %>%
    do(bootstrap_D_score(data = .)) %>%
    ungroup() %>%
    mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) %>%
    round_df(3)
  
  # save to disk
  write_rds(data_estimates_D, file = "models/data_estimates_D.rds", compress = "gz")
  
}

```

## PI scores calculated by trial-type

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_estimates_PI.rds")) {
  
  data_estimates_PI <- read_rds("models/data_estimates_PI.rds")
  
} else {
  
  # Fast calculation of the A statistic - code from Ruscio (2008) supplementary materials
  PI_score <- function(data, i) {
    data_with_indexes <- data[i,] # boot function requires data and index
    x  <- na.omit(data_with_indexes$rt[data_with_indexes$block_type == "con"])
    y  <- na.omit(data_with_indexes$rt[data_with_indexes$block_type == "incon"])
    nx <- length(x)
    ny <- length(y)
    rx <- sum(rank(c(x, y))[1:nx])
    PI <- (rx / nx - (nx + 1) / 2) / ny
    return(PI)
  }
  
  bootstrap_PI_score <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = PI_score, 
                 R         = n_boots, 
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores())
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("norm","basic", "perc", "bca"))
    
    output <- 
      tibble(method   = c("normal", "basic", "percent", "bca"),
             estimate = rep(fit$t0, 4),
             ci_lower = c(results$normal[2], results$basic[4], results$percent[4], results$bca[4]),
             ci_upper = c(results$normal[3], results$basic[5], results$percent[5], results$bca[5]))
    
    return(output)
  }
  
  # bootstrap PI scores 
  data_estimates_PI <- data_outliers_removed %>%
    group_by(unique_id, domain, trial_type) %>%
    do(bootstrap_PI_score(data = .)) %>%
    ungroup() %>%
    mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) %>%
    round_df(3)
  
  # save to disk
  write_rds(data_estimates_PI, file = "models/data_estimates_PI.rds", compress = "gz")
  
}

```

# Proportion different from zero

## *D* scores NEEDS WORK

```{r}

p1 <- 
  data_estimates_D %>%
  arrange(method, estimate) %>%
  group_by(method) %>%
  mutate(ordered_id = row_number()) %>%
  ungroup() %>%
  ggplot() +
  geom_linerange(aes(x = ordered_id, ymin = ci_lower, ymax = ci_upper, color = sig),
                 alpha = 1) +
  geom_point(aes(ordered_id, estimate), size = 0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = c(0.20, 0.85)) +
  scale_color_viridis_d(end = 0.6, direction = -1) +
  xlab("Participant (ranked by D score)") +
  ylab("IRAP D score") +
  labs(color = "95% CI excludes zero") + 
  facet_wrap(~method)

p1

write_rds(p1, "models/p1.rds")

```

```{r}

p2 <- 
  data_estimates_D %>%
  arrange(method, trial_type, estimate) %>%
  group_by(method, trial_type) %>%
  mutate(ordered_id = row_number()) %>%
  ungroup() %>%
  ggplot() +
  geom_linerange(aes(x = ordered_id, ymin = ci_lower, ymax = ci_upper, color = sig),
                 alpha = 1) +
  geom_point(aes(ordered_id, estimate), size = 0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = c(0.20, 0.85)) +
  scale_color_viridis_d(end = 0.6, direction = -1) +
  xlab("Participant (ranked by D score)") +
  ylab("IRAP D score") +
  labs(color = "95% CI excludes zero") + 
  facet_wrap(~method + trial_type)

p2

write_rds(p2, "models/p2.rds")

```

```{r fig.height=25, fig.width=7}

# separated by domain
data_estimates_D %>%
  filter(method == "bca") %>%
  arrange(trial_type, domain, estimate) %>%
  group_by(trial_type, domain) %>%
  mutate(ordered_id = row_number()/n()) %>%
  ungroup() %>%
  ggplot() +
  geom_linerange(aes(x = ordered_id, ymin = ci_lower, ymax = ci_upper, color = sig),
                 alpha = 1) +
  geom_point(aes(ordered_id, estimate), size = 0.5) +
  geom_hline(yintercept = 0, linetype = "dotted") +
  theme_classic() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position = c(0.20, 0.85)) +
  scale_color_viridis_d(end = 0.6, direction = -1) +
  xlab("Participant (ranked by D score)") +
  ylab("IRAP D score") +
  labs(color = "95% CI excludes zero") + 
  facet_wrap(~domain + trial_type, ncol = 8)

```

```{r}

data_estimates_D %>%
  summarize(prop_sig = mean(D_sig)) %>% 
  round_df(3) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_estimates_D %>%
  group_by(domain) %>%
  summarize(prop_sig = mean(D_sig)) %>% 
  arrange(prop_sig) %>%
  round_df(3) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

data_estimates_D %>%
  group_by(domain) %>%
  summarize(prop_sig = mean(D_sig)) %>% 
  ungroup() %>%
  summarize(min_prop_sig = min(prop_sig),
            max_prop_sig = max(prop_sig),
            mean_prop_sig = mean(prop_sig),
            sd_prop_sig = sd(prop_sig)) %>%
  round_df(3) %>%
  gather() %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

```

`r (1 - round(mean(data_estimates_D$D_sig), 3))*100`% of D scores are not significantly different from zero. So, while they might appear to be relatively large (e.g., D = 0.5), their CI does not exclude zero. Put another way, if we treat the zero point as meaningful, we have insufficient evidence to say whether a given D score represents an IRAP effect in `r (1 - round(mean(data_estimates_D$D_sig), 3))*100`% of cases in this large sample (`r nrow(data_estimates_D)/4` participants, `r nrow(data_estimates_D)` total D scores, `r count(distinct(data_estimates_D, domain))` domains)).

## PI scores NEEDS WORK

```{r}


```

# Proportion different from one another

Within domain and trial type

## *D* scores

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_discriminability_D.rds")) {
  
  # data_discriminability_D <- read_rds("models/data_discriminability_D.rds")
  
} else {
  
  # helper function to apply workflow to each resample
  discriminability <- function(data, i) {
    
    data_with_indexes <- data[i,] # boot function requires data and index
    
    estimate <- data_with_indexes$estimate
    ci_lower <- data_with_indexes$ci_lower
    ci_upper <- data_with_indexes$ci_upper
    
    n_estimate <- length(estimate)
    n_ci_lower <- length(ci_lower)
    n_ci_upper <- length(ci_upper)
    
    r_estimate <- sum(rank(c(estimate, ci_lower))[1:n_estimate])
    r_ci_upper <- sum(rank(c(ci_upper, estimate))[1:n_ci_upper])
    
    prob_estimate_inferior_to_ci_lower <- 1 - (r_estimate / n_estimate - (n_estimate + 1) / 2) / n_ci_lower
    prob_estimate_superior_to_ci_upper <- 1 - (r_ci_upper / n_ci_upper - (n_ci_upper + 1) / 2) / n_estimate
    
    probability_estimates_outside_cis <- (prob_estimate_inferior_to_ci_lower + prob_estimate_superior_to_ci_upper)
    
    return(probability_estimates_outside_cis)
    
  }
  
  bootstrap_discriminability <- function(data){
    
    require(dplyr)
    require(boot)
    
    fit <- 
      boot::boot(data      = data, 
                 statistic = discriminability, 
                 R         = n_boots,
                 sim       = "ordinary", 
                 stype     = "i",
                 parallel  = "multicore", 
                 ncpus     = parallel::detectCores())
    
    results <- boot::boot.ci(fit, conf = 0.95, type = c("norm","basic", "perc", "bca"))
    
    output <- 
      tibble(method   = c("normal", "basic", "percent", "bca"),
             estimate = rep(fit$t0, 4),
             ci_lower = c(results$normal[2], results$basic[4], results$percent[4], results$bca[4]),
             ci_upper = c(results$normal[3], results$basic[5], results$percent[5], results$bca[5]))
    
    return(output)
  }

  # bootstrap D scores 
  data_discriminability_D <- data_estimates_D %>%
    select(unique_id, domain, trial_type, estimate, ci_upper, ci_lower) %>%
    group_by(domain, trial_type) %>%
    do(bootstrap_discriminability(data = .)) %>%
    ungroup() %>%
    mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) %>%
    round_df(3)
  
  # save to disk
  write_rds(data_discriminability_D, file = "models/data_discriminability_D.rds", compress = "gz")
  
}

```

## PI scores

```{r}

# bootstrapping has a long execution time, so load saved values if they've already been calculated
if(file.exists("models/data_discriminability_PI.rds")) {
  
  # data_discriminability_D <- read_rds("models/data_discriminability_D.rds")
  
} else {
  
  # bootstrap D scores 
  data_discriminability_PI <- data_estimates_PI %>%
    select(unique_id, domain, trial_type, estimate, ci_upper, ci_lower) %>%
    group_by(domain, trial_type) %>%
    do(bootstrap_discriminability(data = .)) %>%
    ungroup() %>%
    mutate(sig = ifelse((ci_lower < 0 & ci_upper < 0) | (ci_lower > 0 & ci_upper > 0), TRUE, FALSE),
           ci_width = ci_upper - ci_lower) %>%
    round_df(3)
  
  # save to disk
  write_rds(data_discriminability_PI, file = "models/data_discriminability_PI.rds", compress = "gz")
  
}

```

# CI widths as a proportion of observed range

## ANOVA

```{r}

# D scores
## find observed range of D scores for each bootstrapping domain, method, and trial type 
observed_range_estimates_D <- data_estimates_D %>%
  group_by(domain, method, trial_type) %>%
  dplyr::summarize(min = min(estimate, na.rm = TRUE),
                   max = max(estimate, na.rm = TRUE),
                   .groups = "drop") %>%
  mutate(range = max - min) 

## calculate CI / range 
data_ci_width_proportions_D <- data_estimates_D %>%
  # join this data into the original data
  full_join(observed_range_estimates_D, by = c("domain", "method", "trial_type")) %>%
  # calculate ci width as a proportion of observed range
  mutate(ci_width_proportion = ci_width / range) %>%
  # check that factor levels are ordered as desired
  mutate(domain = as.factor(domain),
         Method = fct_relevel(method, "bca", "basic", "normal", "percent"),
         trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4")) %>%
  # calculate most probable value (MAP instead of mean due to distributions) of ci width proportion for each domain, method, and trial type  
  group_by(domain, Method, trial_type) %>%
  do(point_estimate(.$ci_width_proportion, centrality = "MAP")) %>%
  rename(map_ci_width_proportion = MAP)


# PI scores
## find observed range of PI scores for each bootstrapping domain, method, and trial type 
observed_range_estimates_PI <- data_estimates_PI %>%
  group_by(domain, method, trial_type) %>%
  dplyr::summarize(min = min(estimate, na.rm = TRUE),
                   max = max(estimate, na.rm = TRUE),
                   .groups = "drop") %>%
  mutate(range = max - min) 

## calculate CI / range 
data_ci_width_proportions_PI <- data_estimates_PI %>%
  # join this data into the original data
  full_join(observed_range_estimates_PI, by = c("domain", "method", "trial_type")) %>%
  # calculate ci width as a proportion of observed range
  mutate(ci_width_proportion = ci_width / range) %>%
  # check that factor levels are ordered as desired
  mutate(domain = as.factor(domain),
         Method = fct_relevel(method, "bca", "basic", "normal", "percent"),
         trial_type = fct_relevel(trial_type, "tt1", "tt2", "tt3", "tt4")) %>%
  # calculate most probable value (MAP instead of mean due to distributions) of ci width proportion for each domain, method, and trial type  
  group_by(domain, Method, trial_type) %>%
  do(point_estimate(.$ci_width_proportion, centrality = "MAP")) %>%
  rename(map_ci_width_proportion = MAP)


# combine
data_ci_width_proportions_combined <- 
  bind_rows(mutate(data_ci_width_proportions_D, DV_type = "D"),
            mutate(data_ci_width_proportions_PI, DV_type = "PI")) 

# fit anova 
fit_combined <- 
  afex::aov_car(map_ci_width_proportion ~ DV_type * Method * trial_type + Error(domain/(DV_type*Method*trial_type)),
                type = 3,
                data = data_ci_width_proportions_combined)

# results
fit_combined

# correct p values for familywise error rate
tibble(effect = rownames(fit_combined$anova_table),
       p_holm = p.adjust(fit_combined$anova_table$`Pr(>F)`, method = "holm"))

# estimated marginal means
marginal_means_combined <- lsmeans(fit_combined, c("DV_type"), by = "Method")
marginal_means_combined

# post hoc contrasts with corrections for familywise error rate
update(pairs(marginal_means_combined), by = NULL, adjust = "holm")

```

## Plot

```{r}

# fit seperate anovas just to aid plotting
fit_D <- afex::aov_car(map_ci_width_proportion ~ Method * trial_type + Error(domain/(Method*trial_type)),
                       type = 3,
                       data = data_ci_width_proportions_D)

fit_PI <- afex::aov_car(map_ci_width_proportion ~ Method * trial_type + Error(domain/(Method*trial_type)),
                       type = 3,
                       data = data_ci_width_proportions_PI)

# plots
p_D <- 
  afex_plot(fit_D, 
            x = "trial_type", 
            trace = "Method",
            error = "within",
            data_plot = FALSE,
            dodge = 0.25,
            mapping = c("shape", "color"),
            data_arg = list(dodge.width = 0.25)) +
  scale_shape_discrete(labels = c("BCA", "Basic", "Normal", "Percentile")) +
  scale_color_viridis_d(end = 0.8, labels = c("BCA", "Basic", "Normal", "Percentile")) +
  mdthemes::md_theme_linedraw() +
  scale_x_discrete(labels = c("tt1" = "1", "tt2" = "2", "tt3" = "3", "tt4" = "4")) +
  labs(title = "*D* scores",
       x = "Trial type",
       y = "MAP 95% CI width<br/>/ observed range",
       color = "Bootstrapping method",
       shape = "Bootstrapping method") +
  coord_cartesian(ylim = c(0.75, 0.95), expand = TRUE) 

p_PI <- 
  afex_plot(fit_PI, 
            x = "trial_type", 
            trace = "Method",
            error = "within",
            data_plot = FALSE,
            dodge = 0.25,
            mapping = c("shape", "color"),
            data_arg = list(dodge.width = 0.25)) +
  scale_shape_discrete(labels = c("BCA", "Basic", "Normal", "Percentile")) +
  scale_color_viridis_d(end = 0.8, labels = c("BCA", "Basic", "Normal", "Percentile")) +
  mdthemes::md_theme_linedraw() +
    scale_x_discrete(labels = c("tt1" = "1", "tt2" = "2", "tt3" = "3", "tt4" = "4")) +
  labs(title = "PI scores",
       x = "Trial type",
       y = "MAP 95% CI width<br/>/ observed range",
       color = "Bootstrapping method",
       shape = "Bootstrapping method") +
  coord_cartesian(ylim = c(0.75, 0.95), expand = TRUE) 

# combine plots
p_combined <- p_D + p_PI + plot_layout(ncol = 1, nrow = 2, guides = "collect")

p_combined

```

# Session info

```{r}

sessionInfo()

```
